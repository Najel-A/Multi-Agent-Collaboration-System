filebeat.inputs:
  - type: filestream
    id: spark-logs
    enabled: true
    paths:
      - /spark-logs/application_*/*.{log,LOG,out,err}
      - /spark-logs/application_*/*/*.{log,LOG,out,err}
      - /spark-logs/application_*/* # catch files without extensions
      - /spark-logs/application_*/*/* # catch deeper files without extensions
    exclude_files: ['\.gz$', '\.zip$']
    fields:
      service.name: spark
      event.dataset: spark
      source_type: spark_loghub
    fields_under_root: true

    # Handle BOTH common Spark timestamp styles
    multiline:
      pattern: '^(?:\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2},\d{3}|\d{2}/\d{2}/\d{2} \d{2}:\d{2}:\d{2})'
      negate: true
      match: after
      max_lines: 500
      timeout: 5s

processors:
  - add_host_metadata: ~
  - add_cloud_metadata: ~
  - add_docker_metadata: ~

output.logstash:
  hosts: ["logstash:5044"]

setup.template.enabled: false
setup.ilm.enabled: false
logging.to_files: true
